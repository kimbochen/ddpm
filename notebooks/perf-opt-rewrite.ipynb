{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b09ae3eb-1dce-49da-9ea1-4671c5d4f7bf",
   "metadata": {},
   "source": [
    "## Measuring Performance\n",
    "\n",
    "- [A100 Specifications](https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf)\n",
    "- [PyTorch Profiler](https://pytorch.org/tutorials/recipes/recipes/profiler_recipe.html)\n",
    "- [Using CUDA events to measure time](https://discuss.pytorch.org/t/how-to-measure-time-in-pytorch/26964/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacfc879-24c4-42d0-aaa8-36674f25e61c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Baseline\n",
    "\n",
    "`BASELINE_TFLOPS_PER_SEC = 2.096`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83cac72c-80aa-40e1-9c69-5fd3b7cef7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from ddpm import DDPM, ModelConfig, TrainerConfig\n",
    "from model import UNet\n",
    "\n",
    "cfg_m = ModelConfig()\n",
    "cfg_t = TrainerConfig(bs=128, nw=16)\n",
    "\n",
    "img2tensor = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=0.5, std=0.5)  # [0, 1] -> [-1, 1]\n",
    "])\n",
    "ds = CIFAR10('./cifar10', train=True, transform=img2tensor, download=True)\n",
    "dataloader = DataLoader(ds, batch_size=cfg_t.bs, num_workers=cfg_t.nw, drop_last=True)\n",
    "\n",
    "ddpm = DDPM(**asdict(cfg_m)).to('cuda')\n",
    "optimizer = torch.optim.AdamW(ddpm.parameters(), lr=cfg_t.lr)\n",
    "\n",
    "x0, _ = next(iter(dataloader))\n",
    "x0 = x0.to(cfg_t.device)\n",
    "eps = torch.randn_like(x0)\n",
    "t = torch.randint(0, cfg_m.nT, [cfg_t.bs], device=x0.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7bc2858-5635-43e4-acff-421d12dee41a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "DDPM                                          [128, 3, 32, 32]          --\n",
       "├─UNet: 1-1                                   [128, 3, 32, 32]          --\n",
       "│    └─Sequential: 2-1                        [128, 128]                --\n",
       "│    │    └─Linear: 3-1                       [128, 128]                4,224\n",
       "│    │    └─GELU: 3-2                         [128, 128]                --\n",
       "│    │    └─Linear: 3-3                       [128, 128]                16,512\n",
       "│    └─Conv2d: 2-2                            [128, 32, 32, 32]         128\n",
       "│    └─UNetDownsample: 2-3                    [128, 32, 16, 16]         --\n",
       "│    │    └─TimeResNetBlock: 3-4              [128, 32, 32, 32]         26,880\n",
       "│    │    └─TimeResNetBlock: 3-5              [128, 32, 32, 32]         26,880\n",
       "│    │    └─GroupNorm: 3-6                    [128, 32, 32, 32]         64\n",
       "│    │    └─Attention: 3-7                    [128, 32, 32, 32]         16,416\n",
       "│    │    └─DownsampleOutProject: 3-8         [128, 32, 16, 16]         4,128\n",
       "│    └─UNetDownsample: 2-4                    [128, 64, 8, 8]           --\n",
       "│    │    └─TimeResNetBlock: 3-9              [128, 32, 16, 16]         26,880\n",
       "│    │    └─TimeResNetBlock: 3-10             [128, 32, 16, 16]         26,880\n",
       "│    │    └─GroupNorm: 3-11                   [128, 32, 16, 16]         64\n",
       "│    │    └─Attention: 3-12                   [128, 32, 16, 16]         16,416\n",
       "│    │    └─DownsampleOutProject: 3-13        [128, 64, 8, 8]           8,256\n",
       "│    └─UNetDownsample: 2-5                    [128, 128, 4, 4]          --\n",
       "│    │    └─TimeResNetBlock: 3-14             [128, 64, 8, 8]           90,624\n",
       "│    │    └─TimeResNetBlock: 3-15             [128, 64, 8, 8]           90,624\n",
       "│    │    └─GroupNorm: 3-16                   [128, 64, 8, 8]           128\n",
       "│    │    └─Attention: 3-17                   [128, 64, 8, 8]           32,832\n",
       "│    │    └─DownsampleOutProject: 3-18        [128, 128, 4, 4]          32,896\n",
       "│    └─UNetDownsample: 2-6                    [128, 256, 4, 4]          --\n",
       "│    │    └─TimeResNetBlock: 3-19             [128, 128, 4, 4]          328,704\n",
       "│    │    └─TimeResNetBlock: 3-20             [128, 128, 4, 4]          328,704\n",
       "│    │    └─GroupNorm: 3-21                   [128, 128, 4, 4]          256\n",
       "│    │    └─Attention: 3-22                   [128, 128, 4, 4]          65,664\n",
       "│    │    └─Conv2d: 3-23                      [128, 256, 4, 4]          295,168\n",
       "│    └─UNetBlock: 2-7                         [128, 256, 4, 4]          --\n",
       "│    │    └─TimeResNetBlock: 3-24             [128, 256, 4, 4]          1,247,232\n",
       "│    │    └─TimeResNetBlock: 3-25             [128, 256, 4, 4]          1,247,232\n",
       "│    │    └─GroupNorm: 3-26                   [128, 256, 4, 4]          512\n",
       "│    │    └─Attention: 3-27                   [128, 256, 4, 4]          131,328\n",
       "│    └─UNetUpsample: 2-8                      [128, 128, 8, 8]          --\n",
       "│    │    └─TimeResNetBlock: 3-28             [128, 256, 4, 4]          1,640,704\n",
       "│    │    └─TimeResNetBlock: 3-29             [128, 256, 4, 4]          1,640,704\n",
       "│    │    └─GroupNorm: 3-30                   [128, 256, 4, 4]          512\n",
       "│    │    └─Attention: 3-31                   [128, 256, 4, 4]          131,328\n",
       "│    │    └─Sequential: 3-32                  [128, 128, 8, 8]          295,040\n",
       "│    └─UNetUpsample: 2-9                      [128, 64, 16, 16]         --\n",
       "│    │    └─TimeResNetBlock: 3-33             [128, 128, 8, 8]          427,136\n",
       "│    │    └─TimeResNetBlock: 3-34             [128, 128, 8, 8]          427,136\n",
       "│    │    └─GroupNorm: 3-35                   [128, 128, 8, 8]          256\n",
       "│    │    └─Attention: 3-36                   [128, 128, 8, 8]          65,664\n",
       "│    │    └─Sequential: 3-37                  [128, 64, 16, 16]         73,792\n",
       "│    └─UNetUpsample: 2-10                     [128, 32, 32, 32]         --\n",
       "│    │    └─TimeResNetBlock: 3-38             [128, 64, 16, 16]         115,264\n",
       "│    │    └─TimeResNetBlock: 3-39             [128, 64, 16, 16]         115,264\n",
       "│    │    └─GroupNorm: 3-40                   [128, 64, 16, 16]         128\n",
       "│    │    └─Attention: 3-41                   [128, 64, 16, 16]         32,832\n",
       "│    │    └─Sequential: 3-42                  [128, 32, 32, 32]         18,464\n",
       "│    └─UNetUpsample: 2-11                     [128, 32, 32, 32]         --\n",
       "│    │    └─TimeResNetBlock: 3-43             [128, 32, 32, 32]         38,176\n",
       "│    │    └─TimeResNetBlock: 3-44             [128, 32, 32, 32]         38,176\n",
       "│    │    └─GroupNorm: 3-45                   [128, 32, 32, 32]         64\n",
       "│    │    └─Attention: 3-46                   [128, 32, 32, 32]         16,416\n",
       "│    │    └─Conv2d: 3-47                      [128, 32, 32, 32]         9,248\n",
       "│    └─TimeResNetBlock: 2-12                  [128, 32, 32, 32]         --\n",
       "│    │    └─Linear: 3-48                      [128, 64]                 8,256\n",
       "│    │    └─Sequential: 3-49                  [128, 32, 32, 32]         18,528\n",
       "│    │    └─Sequential: 3-50                  [128, 32, 32, 32]         9,312\n",
       "│    │    └─Conv2d: 3-51                      [128, 32, 32, 32]         2,080\n",
       "│    └─Conv2d: 2-13                           [128, 3, 32, 32]          99\n",
       "===============================================================================================\n",
       "Total params: 9,190,211\n",
       "Trainable params: 9,190,211\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 61.22\n",
       "===============================================================================================\n",
       "Input size (MB): 3.15\n",
       "Forward/backward pass size (MB): 2675.11\n",
       "Params size (MB): 36.76\n",
       "Estimated Total Size (MB): 2715.02\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(ddpm, input_data=[x0, eps, t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa58a9b4-888f-402d-bbcc-cbefa21b9647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36732000000000004"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASELINE_TFLOPS = (61.22 * 1e-3) * 2 * 3\n",
    "BASELINE_TFLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73d0715c-86f8-470c-a838-b39b4bbcbf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_steps = 16\n",
    "starts = [torch.cuda.Event(enable_timing=True) for _ in range(n_steps)]\n",
    "ends = [torch.cuda.Event(enable_timing=True) for _ in range(n_steps)]\n",
    "\n",
    "ddpm.train()\n",
    "\n",
    "for i, (x0, _) in zip(range(n_steps), dataloader):\n",
    "    starts[i].record()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x0 = x0.to('cuda')\n",
    "    eps = torch.randn_like(x0)\n",
    "    t = torch.randint(0, cfg_m.nT, [cfg_t.bs], device=x0.device)\n",
    "    \n",
    "    eps_pred = ddpm(x0, eps, t)\n",
    "    loss = F.smooth_l1_loss(eps, eps_pred)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    ends[i].record()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "t = np.mean([s.elapsed_time(e) for s, e in zip(starts, ends)]) / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7195bd-828d-4846-b3ef-70571bd9216b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.096144992132496"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BASELINE_TFLOPS_PER_SEC = BASELINE_TFLOPS / t\n",
    "BASELINE_TFLOPS_PER_SEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8255e43e-57bf-402b-9d94-71b343feed7b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization 1 - Scale Up Batch Size\n",
    "\n",
    "`OPT1_TFLOPS_PER_SEC = 2.404`  \n",
    "1.15x speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c344e7-f9b6-4546-9268-57b751c4b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_TFLOPS_PER_SEC = 2.096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fdd4af0-42a3-4dd0-a1b7-47c3ceaa29b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from ddpm import DDPM, ModelConfig, TrainerConfig\n",
    "from model import UNet\n",
    "\n",
    "cfg_m = ModelConfig()\n",
    "cfg_t = TrainerConfig(bs=320, nw=16)\n",
    "\n",
    "img2tensor = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=0.5, std=0.5)  # [0, 1] -> [-1, 1]\n",
    "])\n",
    "ds = CIFAR10('./cifar10', train=True, transform=img2tensor, download=True)\n",
    "dataloader = DataLoader(ds, batch_size=cfg_t.bs, num_workers=cfg_t.nw, drop_last=True)\n",
    "\n",
    "ddpm = DDPM(**asdict(cfg_m)).to(cfg_t.device)\n",
    "optimizer = torch.optim.AdamW(ddpm.parameters(), lr=cfg_t.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "148ce58b-febc-4f28-b07c-95f41d25f898",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "DDPM                                          [320, 3, 32, 32]          --\n",
       "├─UNet: 1-1                                   [320, 3, 32, 32]          --\n",
       "│    └─Sequential: 2-1                        [320, 128]                --\n",
       "│    │    └─Linear: 3-1                       [320, 128]                4,224\n",
       "│    │    └─GELU: 3-2                         [320, 128]                --\n",
       "│    │    └─Linear: 3-3                       [320, 128]                16,512\n",
       "│    └─Conv2d: 2-2                            [320, 32, 32, 32]         128\n",
       "│    └─UNetDownsample: 2-3                    [320, 32, 16, 16]         --\n",
       "│    │    └─TimeResNetBlock: 3-4              [320, 32, 32, 32]         26,880\n",
       "│    │    └─TimeResNetBlock: 3-5              [320, 32, 32, 32]         26,880\n",
       "│    │    └─GroupNorm: 3-6                    [320, 32, 32, 32]         64\n",
       "│    │    └─Attention: 3-7                    [320, 32, 32, 32]         16,416\n",
       "│    │    └─DownsampleOutProject: 3-8         [320, 32, 16, 16]         4,128\n",
       "│    └─UNetDownsample: 2-4                    [320, 64, 8, 8]           --\n",
       "│    │    └─TimeResNetBlock: 3-9              [320, 32, 16, 16]         26,880\n",
       "│    │    └─TimeResNetBlock: 3-10             [320, 32, 16, 16]         26,880\n",
       "│    │    └─GroupNorm: 3-11                   [320, 32, 16, 16]         64\n",
       "│    │    └─Attention: 3-12                   [320, 32, 16, 16]         16,416\n",
       "│    │    └─DownsampleOutProject: 3-13        [320, 64, 8, 8]           8,256\n",
       "│    └─UNetDownsample: 2-5                    [320, 128, 4, 4]          --\n",
       "│    │    └─TimeResNetBlock: 3-14             [320, 64, 8, 8]           90,624\n",
       "│    │    └─TimeResNetBlock: 3-15             [320, 64, 8, 8]           90,624\n",
       "│    │    └─GroupNorm: 3-16                   [320, 64, 8, 8]           128\n",
       "│    │    └─Attention: 3-17                   [320, 64, 8, 8]           32,832\n",
       "│    │    └─DownsampleOutProject: 3-18        [320, 128, 4, 4]          32,896\n",
       "│    └─UNetDownsample: 2-6                    [320, 256, 4, 4]          --\n",
       "│    │    └─TimeResNetBlock: 3-19             [320, 128, 4, 4]          328,704\n",
       "│    │    └─TimeResNetBlock: 3-20             [320, 128, 4, 4]          328,704\n",
       "│    │    └─GroupNorm: 3-21                   [320, 128, 4, 4]          256\n",
       "│    │    └─Attention: 3-22                   [320, 128, 4, 4]          65,664\n",
       "│    │    └─Conv2d: 3-23                      [320, 256, 4, 4]          295,168\n",
       "│    └─UNetBlock: 2-7                         [320, 256, 4, 4]          --\n",
       "│    │    └─TimeResNetBlock: 3-24             [320, 256, 4, 4]          1,247,232\n",
       "│    │    └─TimeResNetBlock: 3-25             [320, 256, 4, 4]          1,247,232\n",
       "│    │    └─GroupNorm: 3-26                   [320, 256, 4, 4]          512\n",
       "│    │    └─Attention: 3-27                   [320, 256, 4, 4]          131,328\n",
       "│    └─UNetUpsample: 2-8                      [320, 128, 8, 8]          --\n",
       "│    │    └─TimeResNetBlock: 3-28             [320, 256, 4, 4]          1,640,704\n",
       "│    │    └─TimeResNetBlock: 3-29             [320, 256, 4, 4]          1,640,704\n",
       "│    │    └─GroupNorm: 3-30                   [320, 256, 4, 4]          512\n",
       "│    │    └─Attention: 3-31                   [320, 256, 4, 4]          131,328\n",
       "│    │    └─Sequential: 3-32                  [320, 128, 8, 8]          295,040\n",
       "│    └─UNetUpsample: 2-9                      [320, 64, 16, 16]         --\n",
       "│    │    └─TimeResNetBlock: 3-33             [320, 128, 8, 8]          427,136\n",
       "│    │    └─TimeResNetBlock: 3-34             [320, 128, 8, 8]          427,136\n",
       "│    │    └─GroupNorm: 3-35                   [320, 128, 8, 8]          256\n",
       "│    │    └─Attention: 3-36                   [320, 128, 8, 8]          65,664\n",
       "│    │    └─Sequential: 3-37                  [320, 64, 16, 16]         73,792\n",
       "│    └─UNetUpsample: 2-10                     [320, 32, 32, 32]         --\n",
       "│    │    └─TimeResNetBlock: 3-38             [320, 64, 16, 16]         115,264\n",
       "│    │    └─TimeResNetBlock: 3-39             [320, 64, 16, 16]         115,264\n",
       "│    │    └─GroupNorm: 3-40                   [320, 64, 16, 16]         128\n",
       "│    │    └─Attention: 3-41                   [320, 64, 16, 16]         32,832\n",
       "│    │    └─Sequential: 3-42                  [320, 32, 32, 32]         18,464\n",
       "│    └─UNetUpsample: 2-11                     [320, 32, 32, 32]         --\n",
       "│    │    └─TimeResNetBlock: 3-43             [320, 32, 32, 32]         38,176\n",
       "│    │    └─TimeResNetBlock: 3-44             [320, 32, 32, 32]         38,176\n",
       "│    │    └─GroupNorm: 3-45                   [320, 32, 32, 32]         64\n",
       "│    │    └─Attention: 3-46                   [320, 32, 32, 32]         16,416\n",
       "│    │    └─Conv2d: 3-47                      [320, 32, 32, 32]         9,248\n",
       "│    └─TimeResNetBlock: 2-12                  [320, 32, 32, 32]         --\n",
       "│    │    └─Linear: 3-48                      [320, 64]                 8,256\n",
       "│    │    └─Sequential: 3-49                  [320, 32, 32, 32]         18,528\n",
       "│    │    └─Sequential: 3-50                  [320, 32, 32, 32]         9,312\n",
       "│    │    └─Conv2d: 3-51                      [320, 32, 32, 32]         2,080\n",
       "│    └─Conv2d: 2-13                           [320, 3, 32, 32]          99\n",
       "===============================================================================================\n",
       "Total params: 9,190,211\n",
       "Trainable params: 9,190,211\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 153.04\n",
       "===============================================================================================\n",
       "Input size (MB): 7.87\n",
       "Forward/backward pass size (MB): 6687.78\n",
       "Params size (MB): 36.76\n",
       "Estimated Total Size (MB): 6732.41\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "x0, _ = next(iter(dataloader))\n",
    "x0 = x0.to(cfg_t.device)\n",
    "eps = torch.randn_like(x0)\n",
    "t = torch.randint(0, cfg_m.nT, [cfg_t.bs], device=x0.device)\n",
    "summary(ddpm, input_data=[x0, eps, t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "285f0b36-cb94-4034-af57-fdf0ec58be2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91824"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPT1_TFLOPS = (153.04 * 1e-3) * 2 * 3\n",
    "OPT1_TFLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d053250-6f95-41e4-b12b-490126eb7f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n_steps = 16\n",
    "starts = [torch.cuda.Event(enable_timing=True) for _ in range(n_steps)]\n",
    "ends = [torch.cuda.Event(enable_timing=True) for _ in range(n_steps)]\n",
    "\n",
    "ddpm.train()\n",
    "\n",
    "for i, (x0, _) in zip(range(n_steps), dataloader):\n",
    "    starts[i].record()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x0 = x0.to(cfg_t.device)\n",
    "    eps = torch.randn_like(x0)\n",
    "    t = torch.randint(0, cfg_m.nT, [cfg_t.bs], device=x0.device)\n",
    "    \n",
    "    eps_pred = ddpm(x0, eps, t)\n",
    "    loss = F.smooth_l1_loss(eps, eps_pred)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    ends[i].record()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "t = np.mean([s.elapsed_time(e) for s, e in zip(starts, ends)]) / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecd44dbf-2af5-4e10-8b77-c9bcff9865a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.4038481782367884, 1.1468741308381625)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPT1_TFLOPS_PER_SEC = OPT1_TFLOPS / t\n",
    "OPT1_TFLOPS_PER_SEC, OPT1_TFLOPS_PER_SEC / BASELINE_TFLOPS_PER_SEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960bb637-bc36-40d5-b537-1548e0b85487",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization 2 - `torch.compile`\n",
    "\n",
    "`OPT2_TFLOPS_PER_SEC = 3.24`  \n",
    "1.54x speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f87d44fa-342c-4f9f-bb3d-9c27814e7c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_TFLOPS_PER_SEC = 2.096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2ad46a7-6098-4386-aefc-4e9c3e80e443",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from ddpm import DDPM, ModelConfig, TrainerConfig\n",
    "from model import UNet\n",
    "\n",
    "cfg_m = ModelConfig()\n",
    "cfg_t = TrainerConfig(bs=320, nw=16)\n",
    "\n",
    "img2tensor = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=0.5, std=0.5)  # [0, 1] -> [-1, 1]\n",
    "])\n",
    "ds = CIFAR10('./cifar10', train=True, transform=img2tensor, download=True)\n",
    "dataloader = DataLoader(ds, batch_size=cfg_t.bs, num_workers=cfg_t.nw, drop_last=True)\n",
    "\n",
    "ddpm = torch.compile(DDPM(**asdict(cfg_m)).to(cfg_t.device))\n",
    "optimizer = torch.optim.AdamW(ddpm.parameters(), lr=cfg_t.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d344e20-859b-4035-8fd9-9d49c6f89c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91824"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPT2_TFLOPS = (153.04 * 1e-3) * 2 * 3\n",
    "OPT2_TFLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c85a71b-2701-4782-9ebf-3f37515487cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell twice for torch.compile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "n_steps = 16\n",
    "starts = [torch.cuda.Event(enable_timing=True) for _ in range(n_steps)]\n",
    "ends = [torch.cuda.Event(enable_timing=True) for _ in range(n_steps)]\n",
    "\n",
    "ddpm.train()\n",
    "\n",
    "for i, (x0, _) in zip(range(n_steps), dataloader):\n",
    "    starts[i].record()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x0 = x0.to(cfg_t.device)\n",
    "    eps = torch.randn_like(x0)\n",
    "    t = torch.randint(0, cfg_m.nT, [cfg_t.bs], device=x0.device)\n",
    "    \n",
    "    eps_pred = ddpm(x0, eps, t)\n",
    "    loss = F.smooth_l1_loss(eps, eps_pred)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    ends[i].record()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "t = np.mean([s.elapsed_time(e) for s, e in zip(starts, ends)]) / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "037587f8-f553-4794-9d6c-d7c29e828c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.2378172649358796, 1.5447601454846753)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPT2_TFLOPS_PER_SEC = OPT2_TFLOPS / t\n",
    "OPT2_TFLOPS_PER_SEC, OPT2_TFLOPS_PER_SEC / BASELINE_TFLOPS_PER_SEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59445d2f-adb3-4d45-91c6-ad7c77b61aeb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization 3 - Use PyTorch SDPA\n",
    "\n",
    "Using Flash Attention, we significantly lower our memory usage, which allow us to scale the batch size to 2048.\n",
    "\n",
    "- [PyTorch SDPA doc](https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html)\n",
    "- [NanoGPT Usage](https://github.com/karpathy/nanoGPT/blob/master/model.py)\n",
    "\n",
    "`OPT3_TFLOPS_PER_SEC = 6.06`  \n",
    "2.89x speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d14fbcb-1b4b-4764-bae6-a0e5735ba690",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_TFLOPS_PER_SEC = 2.096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b8b4bca-7b94-431a-8158-11cdeb25b5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from ddpm import DDPM, ModelConfig, TrainerConfig\n",
    "from model import UNet\n",
    "\n",
    "cfg_m = ModelConfig()\n",
    "cfg_t = TrainerConfig(bs=2048, nw=16)\n",
    "\n",
    "img2tensor = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=0.5, std=0.5)  # [0, 1] -> [-1, 1]\n",
    "])\n",
    "ds = CIFAR10('./cifar10', train=True, transform=img2tensor, download=True)\n",
    "dataloader = DataLoader(ds, batch_size=cfg_t.bs, num_workers=cfg_t.nw, drop_last=True)\n",
    "\n",
    "ddpm = torch.compile(DDPM(**asdict(cfg_m)).to(cfg_t.device))\n",
    "optimizer = torch.optim.AdamW(ddpm.parameters(), lr=cfg_t.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd0a962-d36e-4cf1-abbc-1a8b64ab58b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "DDPM                                          [2048, 3, 32, 32]         --\n",
       "├─UNet: 1-1                                   [2048, 3, 32, 32]         --\n",
       "│    └─Sequential: 2-1                        [2048, 128]               --\n",
       "│    │    └─Linear: 3-1                       [2048, 128]               4,224\n",
       "│    │    └─GELU: 3-2                         [2048, 128]               --\n",
       "│    │    └─Linear: 3-3                       [2048, 128]               16,512\n",
       "│    └─Conv2d: 2-2                            [2048, 32, 32, 32]        128\n",
       "│    └─UNetDownsample: 2-3                    [2048, 32, 16, 16]        --\n",
       "│    │    └─TimeResNetBlock: 3-4              [2048, 32, 32, 32]        26,880\n",
       "│    │    └─TimeResNetBlock: 3-5              [2048, 32, 32, 32]        26,880\n",
       "│    │    └─GroupNorm: 3-6                    [2048, 32, 32, 32]        64\n",
       "│    │    └─Attention: 3-7                    [2048, 32, 32, 32]        16,416\n",
       "│    │    └─DownsampleOutProject: 3-8         [2048, 32, 16, 16]        4,128\n",
       "│    └─UNetDownsample: 2-4                    [2048, 64, 8, 8]          --\n",
       "│    │    └─TimeResNetBlock: 3-9              [2048, 32, 16, 16]        26,880\n",
       "│    │    └─TimeResNetBlock: 3-10             [2048, 32, 16, 16]        26,880\n",
       "│    │    └─GroupNorm: 3-11                   [2048, 32, 16, 16]        64\n",
       "│    │    └─Attention: 3-12                   [2048, 32, 16, 16]        16,416\n",
       "│    │    └─DownsampleOutProject: 3-13        [2048, 64, 8, 8]          8,256\n",
       "│    └─UNetDownsample: 2-5                    [2048, 128, 4, 4]         --\n",
       "│    │    └─TimeResNetBlock: 3-14             [2048, 64, 8, 8]          90,624\n",
       "│    │    └─TimeResNetBlock: 3-15             [2048, 64, 8, 8]          90,624\n",
       "│    │    └─GroupNorm: 3-16                   [2048, 64, 8, 8]          128\n",
       "│    │    └─Attention: 3-17                   [2048, 64, 8, 8]          32,832\n",
       "│    │    └─DownsampleOutProject: 3-18        [2048, 128, 4, 4]         32,896\n",
       "│    └─UNetDownsample: 2-6                    [2048, 256, 4, 4]         --\n",
       "│    │    └─TimeResNetBlock: 3-19             [2048, 128, 4, 4]         328,704\n",
       "│    │    └─TimeResNetBlock: 3-20             [2048, 128, 4, 4]         328,704\n",
       "│    │    └─GroupNorm: 3-21                   [2048, 128, 4, 4]         256\n",
       "│    │    └─Attention: 3-22                   [2048, 128, 4, 4]         65,664\n",
       "│    │    └─Conv2d: 3-23                      [2048, 256, 4, 4]         295,168\n",
       "│    └─UNetBlock: 2-7                         [2048, 256, 4, 4]         --\n",
       "│    │    └─TimeResNetBlock: 3-24             [2048, 256, 4, 4]         1,247,232\n",
       "│    │    └─TimeResNetBlock: 3-25             [2048, 256, 4, 4]         1,247,232\n",
       "│    │    └─GroupNorm: 3-26                   [2048, 256, 4, 4]         512\n",
       "│    │    └─Attention: 3-27                   [2048, 256, 4, 4]         131,328\n",
       "│    └─UNetUpsample: 2-8                      [2048, 128, 8, 8]         --\n",
       "│    │    └─TimeResNetBlock: 3-28             [2048, 256, 4, 4]         1,640,704\n",
       "│    │    └─TimeResNetBlock: 3-29             [2048, 256, 4, 4]         1,640,704\n",
       "│    │    └─GroupNorm: 3-30                   [2048, 256, 4, 4]         512\n",
       "│    │    └─Attention: 3-31                   [2048, 256, 4, 4]         131,328\n",
       "│    │    └─Sequential: 3-32                  [2048, 128, 8, 8]         295,040\n",
       "│    └─UNetUpsample: 2-9                      [2048, 64, 16, 16]        --\n",
       "│    │    └─TimeResNetBlock: 3-33             [2048, 128, 8, 8]         427,136\n",
       "│    │    └─TimeResNetBlock: 3-34             [2048, 128, 8, 8]         427,136\n",
       "│    │    └─GroupNorm: 3-35                   [2048, 128, 8, 8]         256\n",
       "│    │    └─Attention: 3-36                   [2048, 128, 8, 8]         65,664\n",
       "│    │    └─Sequential: 3-37                  [2048, 64, 16, 16]        73,792\n",
       "│    └─UNetUpsample: 2-10                     [2048, 32, 32, 32]        --\n",
       "│    │    └─TimeResNetBlock: 3-38             [2048, 64, 16, 16]        115,264\n",
       "│    │    └─TimeResNetBlock: 3-39             [2048, 64, 16, 16]        115,264\n",
       "│    │    └─GroupNorm: 3-40                   [2048, 64, 16, 16]        128\n",
       "│    │    └─Attention: 3-41                   [2048, 64, 16, 16]        32,832\n",
       "│    │    └─Sequential: 3-42                  [2048, 32, 32, 32]        18,464\n",
       "│    └─UNetUpsample: 2-11                     [2048, 32, 32, 32]        --\n",
       "│    │    └─TimeResNetBlock: 3-43             [2048, 32, 32, 32]        38,176\n",
       "│    │    └─TimeResNetBlock: 3-44             [2048, 32, 32, 32]        38,176\n",
       "│    │    └─GroupNorm: 3-45                   [2048, 32, 32, 32]        64\n",
       "│    │    └─Attention: 3-46                   [2048, 32, 32, 32]        16,416\n",
       "│    │    └─Conv2d: 3-47                      [2048, 32, 32, 32]        9,248\n",
       "│    └─TimeResNetBlock: 2-12                  [2048, 32, 32, 32]        --\n",
       "│    │    └─Linear: 3-48                      [2048, 64]                8,256\n",
       "│    │    └─Sequential: 3-49                  [2048, 32, 32, 32]        18,528\n",
       "│    │    └─Sequential: 3-50                  [2048, 32, 32, 32]        9,312\n",
       "│    │    └─Conv2d: 3-51                      [2048, 32, 32, 32]        2,080\n",
       "│    └─Conv2d: 2-13                           [2048, 3, 32, 32]         99\n",
       "===============================================================================================\n",
       "Total params: 9,190,211\n",
       "Trainable params: 9,190,211\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 979.46\n",
       "===============================================================================================\n",
       "Input size (MB): 50.35\n",
       "Forward/backward pass size (MB): 42801.82\n",
       "Params size (MB): 36.76\n",
       "Estimated Total Size (MB): 42888.93\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "x0, _ = next(iter(dataloader))\n",
    "x0 = x0.to(cfg_t.device)\n",
    "eps = torch.randn_like(x0)\n",
    "t = torch.randint(0, cfg_m.nT, [cfg_t.bs], device=x0.device)\n",
    "summary(DDPM(**asdict(cfg_m)).to(cfg_t.device), input_data=[x0, eps, t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d85e0e-120b-4e11-8fdb-e96ce70064d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.876760000000001"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPT3_TFLOPS = (979.46 * 1e-3) * 2 * 3\n",
    "OPT3_TFLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c9a959-d1aa-4d9b-87f0-3669d297f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell twice for torch.compile\n",
    "import numpy as np\n",
    "\n",
    "n_steps = 16\n",
    "starts = [torch.cuda.Event(enable_timing=True) for _ in range(n_steps)]\n",
    "ends = [torch.cuda.Event(enable_timing=True) for _ in range(n_steps)]\n",
    "\n",
    "ddpm.train()\n",
    "\n",
    "for i, (x0, _) in zip(range(n_steps), dataloader):\n",
    "    starts[i].record()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    x0 = x0.to(cfg_t.device)\n",
    "    eps = torch.randn_like(x0)\n",
    "    t = torch.randint(0, cfg_m.nT, [cfg_t.bs], device=x0.device)\n",
    "    \n",
    "    eps_pred = ddpm(x0, eps, t)\n",
    "    loss = F.smooth_l1_loss(eps, eps_pred)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    ends[i].record()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "t = np.mean([s.elapsed_time(e) for s, e in zip(starts, ends)]) / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50ce00f8-1bca-4e19-a369-afe64f7b5a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.0628220806029995, 2.8925677865472323)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPT3_TFLOPS_PER_SEC = OPT3_TFLOPS / t\n",
    "OPT3_TFLOPS_PER_SEC, OPT3_TFLOPS_PER_SEC / BASELINE_TFLOPS_PER_SEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9ee247-7bfb-4565-9270-579baa81c41e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization 4 - Mixed-Precision Training\n",
    "\n",
    "Lowering to 16-bit precision lowers the memory requirements, so we further increase the batch size to 3072.\n",
    "\n",
    "- [Tutorial 1](https://pytorch.org/blog/what-every-user-should-know-about-mixed-precision-training-in-pytorch/)\n",
    "- [Tutorial 2](https://pytorch.org/blog/accelerating-training-on-nvidia-gpus-with-pytorch-automatic-mixed-precision/)\n",
    "\n",
    "`OPT4_TFLOPS_PER_SEC = 16.47`  \n",
    "7.86x speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b768f879-eae0-42c3-bb81-5e4876573df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_TFLOPS_PER_SEC = 2.096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "583cc130-c953-4f4f-a37c-9aa7a28d770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from ddpm import DDPM, ModelConfig, TrainerConfig\n",
    "from model import UNet\n",
    "\n",
    "cfg_m = ModelConfig()\n",
    "cfg_t = TrainerConfig(bs=3072, nw=16)\n",
    "\n",
    "img2tensor = T.Compose([\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=0.5, std=0.5)  # [0, 1] -> [-1, 1]\n",
    "])\n",
    "ds = CIFAR10('./cifar10', train=True, transform=img2tensor, download=True)\n",
    "dataloader = DataLoader(ds, batch_size=cfg_t.bs, num_workers=cfg_t.nw, drop_last=True)\n",
    "\n",
    "ddpm = torch.compile(DDPM(**asdict(cfg_m)).to(cfg_t.device))\n",
    "optimizer = torch.optim.AdamW(ddpm.parameters(), lr=cfg_t.lr)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9289da-a0f3-4d1f-8b51-928dace94b33",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "DDPM                                          [3072, 3, 32, 32]         --\n",
       "├─UNet: 1-1                                   [3072, 3, 32, 32]         --\n",
       "│    └─Sequential: 2-1                        [3072, 128]               --\n",
       "│    │    └─Linear: 3-1                       [3072, 128]               4,224\n",
       "│    │    └─GELU: 3-2                         [3072, 128]               --\n",
       "│    │    └─Linear: 3-3                       [3072, 128]               16,512\n",
       "│    └─Conv2d: 2-2                            [3072, 32, 32, 32]        128\n",
       "│    └─UNetDownsample: 2-3                    [3072, 32, 16, 16]        --\n",
       "│    │    └─TimeResNetBlock: 3-4              [3072, 32, 32, 32]        26,880\n",
       "│    │    └─TimeResNetBlock: 3-5              [3072, 32, 32, 32]        26,880\n",
       "│    │    └─GroupNorm: 3-6                    [3072, 32, 32, 32]        64\n",
       "│    │    └─Attention: 3-7                    [3072, 32, 32, 32]        16,416\n",
       "│    │    └─DownsampleOutProject: 3-8         [3072, 32, 16, 16]        4,128\n",
       "│    └─UNetDownsample: 2-4                    [3072, 64, 8, 8]          --\n",
       "│    │    └─TimeResNetBlock: 3-9              [3072, 32, 16, 16]        26,880\n",
       "│    │    └─TimeResNetBlock: 3-10             [3072, 32, 16, 16]        26,880\n",
       "│    │    └─GroupNorm: 3-11                   [3072, 32, 16, 16]        64\n",
       "│    │    └─Attention: 3-12                   [3072, 32, 16, 16]        16,416\n",
       "│    │    └─DownsampleOutProject: 3-13        [3072, 64, 8, 8]          8,256\n",
       "│    └─UNetDownsample: 2-5                    [3072, 128, 4, 4]         --\n",
       "│    │    └─TimeResNetBlock: 3-14             [3072, 64, 8, 8]          90,624\n",
       "│    │    └─TimeResNetBlock: 3-15             [3072, 64, 8, 8]          90,624\n",
       "│    │    └─GroupNorm: 3-16                   [3072, 64, 8, 8]          128\n",
       "│    │    └─Attention: 3-17                   [3072, 64, 8, 8]          32,832\n",
       "│    │    └─DownsampleOutProject: 3-18        [3072, 128, 4, 4]         32,896\n",
       "│    └─UNetDownsample: 2-6                    [3072, 256, 4, 4]         --\n",
       "│    │    └─TimeResNetBlock: 3-19             [3072, 128, 4, 4]         328,704\n",
       "│    │    └─TimeResNetBlock: 3-20             [3072, 128, 4, 4]         328,704\n",
       "│    │    └─GroupNorm: 3-21                   [3072, 128, 4, 4]         256\n",
       "│    │    └─Attention: 3-22                   [3072, 128, 4, 4]         65,664\n",
       "│    │    └─Conv2d: 3-23                      [3072, 256, 4, 4]         295,168\n",
       "│    └─UNetBlock: 2-7                         [3072, 256, 4, 4]         --\n",
       "│    │    └─TimeResNetBlock: 3-24             [3072, 256, 4, 4]         1,247,232\n",
       "│    │    └─TimeResNetBlock: 3-25             [3072, 256, 4, 4]         1,247,232\n",
       "│    │    └─GroupNorm: 3-26                   [3072, 256, 4, 4]         512\n",
       "│    │    └─Attention: 3-27                   [3072, 256, 4, 4]         131,328\n",
       "│    └─UNetUpsample: 2-8                      [3072, 128, 8, 8]         --\n",
       "│    │    └─TimeResNetBlock: 3-28             [3072, 256, 4, 4]         1,640,704\n",
       "│    │    └─TimeResNetBlock: 3-29             [3072, 256, 4, 4]         1,640,704\n",
       "│    │    └─GroupNorm: 3-30                   [3072, 256, 4, 4]         512\n",
       "│    │    └─Attention: 3-31                   [3072, 256, 4, 4]         131,328\n",
       "│    │    └─Sequential: 3-32                  [3072, 128, 8, 8]         295,040\n",
       "│    └─UNetUpsample: 2-9                      [3072, 64, 16, 16]        --\n",
       "│    │    └─TimeResNetBlock: 3-33             [3072, 128, 8, 8]         427,136\n",
       "│    │    └─TimeResNetBlock: 3-34             [3072, 128, 8, 8]         427,136\n",
       "│    │    └─GroupNorm: 3-35                   [3072, 128, 8, 8]         256\n",
       "│    │    └─Attention: 3-36                   [3072, 128, 8, 8]         65,664\n",
       "│    │    └─Sequential: 3-37                  [3072, 64, 16, 16]        73,792\n",
       "│    └─UNetUpsample: 2-10                     [3072, 32, 32, 32]        --\n",
       "│    │    └─TimeResNetBlock: 3-38             [3072, 64, 16, 16]        115,264\n",
       "│    │    └─TimeResNetBlock: 3-39             [3072, 64, 16, 16]        115,264\n",
       "│    │    └─GroupNorm: 3-40                   [3072, 64, 16, 16]        128\n",
       "│    │    └─Attention: 3-41                   [3072, 64, 16, 16]        32,832\n",
       "│    │    └─Sequential: 3-42                  [3072, 32, 32, 32]        18,464\n",
       "│    └─UNetUpsample: 2-11                     [3072, 32, 32, 32]        --\n",
       "│    │    └─TimeResNetBlock: 3-43             [3072, 32, 32, 32]        38,176\n",
       "│    │    └─TimeResNetBlock: 3-44             [3072, 32, 32, 32]        38,176\n",
       "│    │    └─GroupNorm: 3-45                   [3072, 32, 32, 32]        64\n",
       "│    │    └─Attention: 3-46                   [3072, 32, 32, 32]        16,416\n",
       "│    │    └─Conv2d: 3-47                      [3072, 32, 32, 32]        9,248\n",
       "│    └─TimeResNetBlock: 2-12                  [3072, 32, 32, 32]        --\n",
       "│    │    └─Linear: 3-48                      [3072, 64]                8,256\n",
       "│    │    └─Sequential: 3-49                  [3072, 32, 32, 32]        18,528\n",
       "│    │    └─Sequential: 3-50                  [3072, 32, 32, 32]        9,312\n",
       "│    │    └─Conv2d: 3-51                      [3072, 32, 32, 32]        2,080\n",
       "│    └─Conv2d: 2-13                           [3072, 3, 32, 32]         99\n",
       "===============================================================================================\n",
       "Total params: 9,190,211\n",
       "Trainable params: 9,190,211\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 1.47\n",
       "===============================================================================================\n",
       "Input size (MB): 75.52\n",
       "Forward/backward pass size (MB): 64202.74\n",
       "Params size (MB): 36.76\n",
       "Estimated Total Size (MB): 64315.02\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "x0, _ = next(iter(dataloader))\n",
    "x0 = x0.to(cfg_t.device)\n",
    "eps = torch.randn_like(x0)\n",
    "t = torch.randint(0, cfg_m.nT, [cfg_t.bs], device=x0.device)\n",
    "summary(DDPM(**asdict(cfg_m)).to(cfg_t.device), input_data=[x0, eps, t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5893937-0bc1-49e0-b60f-46d7ecc0dc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.82"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPT4_TFLOPS = 1.47 * 2 * 3\n",
    "OPT4_TFLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72184a53-4465-4dc0-aa0c-d06718c12eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell twice for torch.compile\n",
    "import numpy as np\n",
    "\n",
    "n_steps = 16\n",
    "starts = [torch.cuda.Event(enable_timing=True) for _ in range(n_steps)]\n",
    "ends = [torch.cuda.Event(enable_timing=True) for _ in range(n_steps)]\n",
    "\n",
    "ddpm.train()\n",
    "\n",
    "for i, (x0, _) in zip(range(n_steps), dataloader):\n",
    "    starts[i].record()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x0 = x0.to(cfg_t.device)\n",
    "    eps = torch.randn_like(x0)\n",
    "    t = torch.randint(0, cfg_m.nT, [cfg_t.bs], device=x0.device)\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        eps_pred = ddpm(x0, eps, t)\n",
    "        loss = F.smooth_l1_loss(eps, eps_pred)\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    ends[i].record()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "t = np.mean([s.elapsed_time(e) for s, e in zip(starts, ends)]) / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3e5fb93-d70c-4ff6-af86-60fbe40e6a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.46762723679398, 7.856692383966593)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPT4_TFLOPS_PER_SEC = OPT4_TFLOPS / t\n",
    "OPT4_TFLOPS_PER_SEC, OPT4_TFLOPS_PER_SEC / BASELINE_TFLOPS_PER_SEC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d53567-b596-4d9c-a6c8-70244c85ca7c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Optimization 5 - Use FFCV for Data Loading\n",
    "\n",
    "- [FFCV GitHub Repo](https://github.com/libffcv/ffcv)\n",
    "- [MosaicML Example Notebook](https://colab.research.google.com/github/mosaicml/composer/blob/75dabff3f5715f02bfc32cc23c557ba4042c462d/examples/ffcv_dataloaders.ipynb)\n",
    "- [FFCV API Reference](https://docs.ffcv.io/api_reference.html)\n",
    "\n",
    "`OPT5_TFLOPS_PER_SEC = 16.70`  \n",
    "7.97x speedup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131502bb-589c-488f-b5e3-58dae2a3fd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASELINE_TFLOPS_PER_SEC = 2.096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5961429a-0c72-47a6-8bee-5f953f63d414",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/numba/np/ufunc/parallel.py:371: NumbaWarning: \u001b[1mThe TBB threading layer requires TBB version 2021 update 6 or later i.e., TBB_INTERFACE_VERSION >= 12060. Found TBB_INTERFACE_VERSION = 12050. The TBB threading layer is disabled.\u001b[0m\n",
      "  warnings.warn(problem)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import asdict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "from ddpm import DDPM, ModelConfig, TrainerConfig\n",
    "from model import UNet\n",
    "\n",
    "cfg_m = ModelConfig()\n",
    "cfg_t = TrainerConfig(bs=3072, nw=16)\n",
    "\n",
    "ddpm = torch.compile(DDPM(**asdict(cfg_m)).to(cfg_t.device))\n",
    "optimizer = torch.optim.AdamW(ddpm.parameters(), lr=cfg_t.lr)\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "320931d7-8157-48cf-bc96-48bf729c14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import ffcv.transforms as T\n",
    "from ffcv.fields import RGBImageField\n",
    "from ffcv.fields.decoders import SimpleRGBImageDecoder\n",
    "from ffcv.loader import Loader, OrderOption\n",
    "from ffcv.writer import DatasetWriter\n",
    "\n",
    "if not Path('./cifar10.beton').exists():\n",
    "    ds = CIFAR10('./cifar10', train=True, download=True)\n",
    "    writer = DatasetWriter('./cifar10.beton', {'image': RGBImageField(max_resolution=32)})\n",
    "    writer.from_indexed_dataset(ds)\n",
    "\n",
    "img_tsfms = [\n",
    "    SimpleRGBImageDecoder(),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.ToDevice(torch.device(cfg_t.device)),\n",
    "    T.ToTorchImage(),\n",
    "    T.NormalizeImage(  # [0, 255] -> [-1, 1]\n",
    "        mean=np.array([127.5, 127.5, 127.5]),\n",
    "        std=np.array([127.5, 127.5, 127.5]),\n",
    "        type=np.float32\n",
    "    )\n",
    "]\n",
    "dataloader = Loader(\n",
    "    './cifar10.beton', batch_size=cfg_t.bs, num_workers=cfg_t.nw, drop_last=True, os_cache=True,\n",
    "    order=OrderOption.RANDOM, pipelines={'image': img_tsfms}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e53307-c63d-4a96-a7e3-fca30518f9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.82"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPT5_TFLOPS = 1.47 * 2 * 3\n",
    "OPT5_TFLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119ee78c-b58f-486f-90e0-a51af9826080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell twice for torch.compile\n",
    "import numpy as np\n",
    "\n",
    "n_steps = 16\n",
    "starts = [torch.cuda.Event(enable_timing=True) for _ in range(n_steps)]\n",
    "ends = [torch.cuda.Event(enable_timing=True) for _ in range(n_steps)]\n",
    "\n",
    "ddpm.train()\n",
    "\n",
    "for i, (x0, ) in zip(range(n_steps), dataloader):\n",
    "    starts[i].record()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x0 = x0.to(cfg_t.device)\n",
    "    eps = torch.randn_like(x0)\n",
    "    t = torch.randint(0, cfg_m.nT, [cfg_t.bs], device=x0.device)\n",
    "\n",
    "    with torch.cuda.amp.autocast():\n",
    "        eps_pred = ddpm(x0, eps, t)\n",
    "        loss = F.smooth_l1_loss(eps, eps_pred)\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    ends[i].record()\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "t = np.mean([s.elapsed_time(e) for s, e in zip(starts, ends)]) / 1000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf862b48-f53c-407a-a145-91d882a38e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16.70376585232557, 7.96935393717823)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPT5_TFLOPS_PER_SEC = OPT5_TFLOPS / t\n",
    "OPT5_TFLOPS_PER_SEC, OPT5_TFLOPS_PER_SEC / BASELINE_TFLOPS_PER_SEC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
