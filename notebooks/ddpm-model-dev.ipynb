{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28a3f852-48d5-490c-b92c-2d136cdab185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff48dc9e-f3be-475f-b361-dadc821a3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dims(x, shape):\n",
    "    assert x.size() == shape, f'Expected {shape}, got {x.size()}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bd2f32-5b1f-4707-bb17-61bec0453300",
   "metadata": {},
   "source": [
    "## Weight-Standardized Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc3ac8f4-f21a-4a16-8c53-798842151d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSConv2d(nn.Conv2d):\n",
    "    '''\n",
    "    Weight-Standardized Convolution\n",
    "    https://arxiv.org/abs/1903.10520\n",
    "    '''\n",
    "    def __init__(self, *args, eps=1e-5, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = self.weight.mean(dim=1, keepdim=True)\n",
    "        var = self.weight.var(dim=1, correction=0, keepdim=True)\n",
    "        norm_weight = (self.weight - mean) * torch.rsqrt(var + self.eps)\n",
    "        out = F.conv2d(\n",
    "            x, norm_weight,\n",
    "            self.bias, self.stride, self.padding, self.dilation, self.groups\n",
    "        )\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ccb25e-2694-4a97-b60b-b7fac88e0dd1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41a9500-95af-4ba5-b916-25acc50e085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3985)\n",
    "x = torch.rand([2, 32, 128, 128])\n",
    "ws_conv = WSConv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1).to(x.device)\n",
    "check_dims(ws_conv(x), (2, 64, 128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e5cc66-7562-464f-bf68-f2c1ee6bdd73",
   "metadata": {},
   "source": [
    "## Time-conditioned ResNet Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "847cf054-697f-4aef-908b-6f90aa98ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeResNetBlock(nn.Module):\n",
    "    '''\n",
    "    B: Batch size\n",
    "    D: in_dim\n",
    "    E: out_dim\n",
    "    F: out_dim * 2\n",
    "    G: E + F = out_dim * 3\n",
    "    '''\n",
    "    def __init__(self, in_dim, out_dim, t_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj_t = nn.Linear(t_dim, out_dim*2)\n",
    "        self.conv1 = nn.Sequential(\n",
    "            WSConv2d(in_dim, out_dim, kernel_size=3, padding=1),\n",
    "            nn.GroupNorm(num_groups=8, num_channels=out_dim)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            WSConv2d(out_dim, out_dim, kernel_size=3, padding=1),\n",
    "            nn.GroupNorm(num_groups=8, num_channels=out_dim)\n",
    "        )\n",
    "        if in_dim != out_dim:\n",
    "            self.rconv = nn.Conv2d(in_dim, out_dim, kernel_size=1)\n",
    "        else:\n",
    "            self.rconv = nn.Identity()\n",
    "\n",
    "    def forward(self, x_BDHW, t_embd_BT):\n",
    "        t_embd_BF = self.proj_t(t_embd_BT)\n",
    "        scale_BE, shift_BE = t_embd_BF.reshape(*t_embd_BF.shape, 1, 1).chunk(2, dim=1)\n",
    "        h_BEHW = self.conv1(x_BDHW)\n",
    "        h_BEHW = F.silu(h_BEHW * (scale_BE + 1) + shift_BE)\n",
    "        h_BEHW = self.conv2(h_BEHW)\n",
    "        x_BEHW = h_BEHW + self.rconv(x_BDHW)\n",
    "        return x_BEHW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb9136a-9fd9-45e2-a146-4f1b6fea524a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f0ee06a-1657-4f26-9c3b-87db16f5e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "D = 32\n",
    "E = 64\n",
    "F_ = 2 * E\n",
    "T_ = D * 4\n",
    "H, W = 128, 128\n",
    "\n",
    "torch.manual_seed(3985)\n",
    "x_BDHW = torch.rand([B, D, H, W], device='cuda')\n",
    "t_BT = torch.rand([B, T_], device=x_BDHW.device)\n",
    "model = TimeResNetBlock(D, E, T_).to(x_BDHW.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c2ed5b7-bbec-43fa-b0e5-18d48d8d3096",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_embd_BF = model.proj_t(t_embd_BT)\n",
    "check_dims(t_embd_BF, (B, F_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5331746c-4488-43bd-9acb-4ca5ed6cb737",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_BE, shift_BE = t_embd_BF.reshape(*t_embd_BF.shape, 1, 1).chunk(2, dim=1)\n",
    "check_dims(scale_BE, (B, E, 1, 1))\n",
    "check_dims(shift_BE, (B, E, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1843e9a7-8911-4ed0-9cdc-9e83f37bbf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_BEHW = model.conv1(x_BDHW)\n",
    "check_dims(h_BEHW, (B, E, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78d2d10b-dec6-4d31-ab64-723ee400e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_BEHW = F.silu(h_BEHW * (scale_BE + 1) + shift_BE)\n",
    "check_dims(h_BEHW, (B, E, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "441a51bc-8f06-4589-bf34-633c06d6daa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_BEHW = model.conv2(h_BEHW)\n",
    "check_dims(h_BEHW, (B, E, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ef454a1-e4e2-4da3-9e49-e13bc52e3869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 64, 128, 128]), torch.Size([2, 64, 128, 128]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rconv(x_BDHW).size(), h_BEHW.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "460ce5ed-6527-4790-aef2-d5342c975575",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BEHW = h_BEHW + model.rconv(x_BDHW)\n",
    "check_dims(x_BEHW, (B, E, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b554fe10-6fc7-4f54-baac-440d53ca91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dims(model(x_BDHW, t_BT), (B, E, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9146af1b-2dcb-4b76-8d6b-3274aa84ca08",
   "metadata": {},
   "source": [
    "## Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1522be39-095b-48e8-8d12-715c0488a105",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_embd, n_heads=4, d_head=32):\n",
    "        super().__init__()\n",
    "        d_hid = n_heads * d_head\n",
    "\n",
    "        self.n_heads = n_heads\n",
    "        self.d_head = d_head\n",
    "        self.attn_proj = nn.Conv2d(d_embd, d_hid*3, kernel_size=1, bias=False)\n",
    "        self.scale = d_head ** -0.5\n",
    "        self.out_proj = nn.Conv2d(d_hid, d_embd, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        qkv = self.attn_proj(x).chunk(3, dim=1)\n",
    "        to_attn_head = lambda z: z.reshape(B, self.n_heads, self.d_head, -1)\n",
    "        q, k, v = map(to_attn_head, qkv)\n",
    "\n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        score = F.softmax(attn, dim=-1)\n",
    "        y = score @ v\n",
    "        y = y.transpose(-2, -1).reshape(B, -1, H, W)\n",
    "        out = self.out_proj(y)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568e2fc7-9c04-4023-bcc0-19439d5e5a99",
   "metadata": {},
   "source": [
    "## UNet Downsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c0ab78c-dcf7-4242-b547-2e5a18376dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownsampleOutProject(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.out_proj = nn.Conv2d(4*in_dim, out_dim, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.size()\n",
    "        x = x.reshape(B, 4*C, H//2, W//2)\n",
    "        x = self.out_proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNetDownsample(nn.Module):\n",
    "    '''\n",
    "    B: Batch size\n",
    "    D: in_dim\n",
    "    E: out_dim\n",
    "    T: t_dim\n",
    "    H, W: Last 2 dimensions of x\n",
    "    Ho, Wo: (H, W) if is_last else (H // 2, W // 2)\n",
    "    '''\n",
    "    def __init__(self, in_dim, out_dim, t_dim, is_last=False):\n",
    "        super().__init__()\n",
    "        self.block1 = TimeResNetBlock(in_dim, in_dim, t_dim)\n",
    "        self.block2 = TimeResNetBlock(in_dim, in_dim, t_dim)\n",
    "        self.norm = nn.GroupNorm(num_groups=1, num_channels=in_dim)\n",
    "        self.attn = Attention(in_dim)\n",
    "\n",
    "        if is_last:\n",
    "            self.dsample = nn.Conv2d(in_dim, out_dim, kernel_size=3, padding=1)\n",
    "        else:\n",
    "            self.dsample = DownsampleOutProject(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x_BDHW, t_embd_BT):\n",
    "        fmap1_BDHW = self.block1(x_BDHW, t_embd_BT)\n",
    "        fmap2_BDHW = self.block2(fmap1_BDHW, t_embd_BT)\n",
    "        x_BDHW = self.attn(self.norm(fmap2_BDHW)) + fmap2_BDHW\n",
    "        x_BDHoWo = self.dsample(x_BDHW)\n",
    "        return x_BDHoWo, fmap1_BDHW, fmap2_BDHW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268b25f8-d2bb-46d5-9aa5-b7c7049cbf9a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210fcf7d-9a20-46a9-844d-cb54fbf2aed7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Case 1: `is_last = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0cc67160-7fd4-4ddd-9abf-62e9f0ff4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "D = 32\n",
    "H, W = 128, 128\n",
    "E = 64\n",
    "T_ = 128\n",
    "Ho, Wo = H // 2, W // 2\n",
    "\n",
    "torch.manual_seed(3985)\n",
    "x_BDHW = torch.rand([B, D, H, W], device='cuda')\n",
    "t_embd_BT = torch.rand([B, T_], device=x_BDHW.device)\n",
    "model = UNetDownsample(D, E, T_).to(x_BDHW.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "535ae6e7-ddfd-4aab-a624-3b0f802ba5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap1_BDHW = model.block1(x_BDHW, t_embd_BT)\n",
    "check_dims(fmap1_BDHW, (B, D, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9476ba03-fa69-49e2-96ab-13cdc49ab5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap2_BDHW = model.block2(fmap1_BDHW, t_embd_BT)\n",
    "check_dims(fmap2_BDHW, (B, D, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdb9a79a-cc87-4257-a4df-7fdc9495a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BDHW = model.attn(model.norm(fmap2_BDHW)) + fmap2_BDHW\n",
    "check_dims(x_BDHW, (B, D, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "13d3b890-5b8f-47b1-891b-7a6982416c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BEHoWo = model.dsample(x_BDHW)\n",
    "check_dims(x_BEHoWo, (B, E, Ho, Wo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88bc2d36-5b56-4ac2-a01e-cbdd9ad1e804",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = model(x_BDHW, t_embd_BT)\n",
    "check_dims(a, (B, E, Ho, Wo))\n",
    "check_dims(b, (B, D, H, W))\n",
    "check_dims(c, (B, D, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7f2ef4-4595-44db-aa0a-12d893b3a940",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Case 2 `is_last = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f048d51-9f2f-4d3d-a2bd-78b1d15821e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ho, Wo = H, W\n",
    "model = UNetDownsample(D, E, T_, is_last=True).to(x_BDHW.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "85aeae0a-3187-4633-8255-e78b96ee0bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap1_BDHW = model.block1(x_BDHW, t_embd_BT)\n",
    "check_dims(fmap1_BDHW, (B, D, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d82eb4b0-7689-4c95-95ed-0859340081ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fmap2_BDHW = model.block2(fmap1_BDHW, t_embd_BT)\n",
    "check_dims(fmap2_BDHW, (B, D, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b3d4dd4-ea2f-4dc0-a4d9-1fc1f0e8978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BDHW = model.attn(model.norm(fmap2_BDHW)) + fmap2_BDHW\n",
    "check_dims(x_BDHW, (B, D, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5bc77367-4b2b-474e-8a63-6376be0f793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BEHoWo = model.dsample(x_BDHW)\n",
    "check_dims(x_BEHoWo, (B, E, Ho, Wo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8609695f-db0e-4fe8-ab86-fc63a2f727af",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = model(x_BDHW, t_embd_BT)\n",
    "check_dims(a, (B, E, Ho, Wo))\n",
    "check_dims(b, (B, D, H, W))\n",
    "check_dims(c, (B, D, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39d85c1-bef8-461d-ba86-2507a59b2f69",
   "metadata": {},
   "source": [
    "## UNet Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74554d7e-4b2c-4798-9461-70cec8c8fbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetUpsample(nn.Module):\n",
    "    '''\n",
    "    B: Batch size\n",
    "    D: in_dim\n",
    "    E: out_dim\n",
    "    F: in_dim + out_dim\n",
    "    T: t_dim\n",
    "    H, W: Last 2 dimensions of x\n",
    "    Ho, Wo: (H, W) if is_last else (H * 2, W * 2)\n",
    "    '''\n",
    "    def __init__(self, in_dim, out_dim, t_dim, is_last=False):\n",
    "        super().__init__()\n",
    "        self.block1 = TimeResNetBlock(in_dim+out_dim, out_dim, t_dim)\n",
    "        self.block2 = TimeResNetBlock(in_dim+out_dim, out_dim, t_dim)\n",
    "        self.norm = nn.GroupNorm(num_groups=1, num_channels=out_dim)\n",
    "        self.attn = Attention(out_dim)\n",
    "\n",
    "        if is_last:\n",
    "            self.usample = nn.Conv2d(out_dim, in_dim, kernel_size=3, padding=1)\n",
    "        else:\n",
    "            self.usample = nn.Sequential(\n",
    "                nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "                nn.Conv2d(out_dim, in_dim, kernel_size=3, padding=1)\n",
    "            )\n",
    "\n",
    "    def forward(self, x_BEHW, fmap1_BDHW, fmap2_BDHW, t_embd_BT):\n",
    "        x_BFHW = torch.cat([x_BEHW, fmap1_BDHW], dim=1)\n",
    "        x_BEHW = self.block1(x_BFHW, t_embd_BT)\n",
    "\n",
    "        x_BFHW = torch.cat([x_BEHW, fmap2_BDHW], dim=1)\n",
    "        x_BEHW = self.block2(x_BFHW, t_embd_BT)\n",
    "\n",
    "        x_BEHW = self.attn(self.norm(x_BEHW)) + x_BEHW\n",
    "        x_BDHoWo = self.usample(x_BEHW)\n",
    "\n",
    "        return x_BDHoWo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5687ce9a-1cc7-4cdd-bed4-de05ac106ac8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf4fac-f436-4b58-bb49-45ce2c2db30c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Case 1: `is_last = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f86d067-71bd-4ff5-893a-92c097ae1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "D = 32\n",
    "H, W = 128, 128\n",
    "E = 64\n",
    "F_ = D + E\n",
    "T_ = 128\n",
    "Ho, Wo = H * 2, W * 2\n",
    "\n",
    "torch.manual_seed(3985)\n",
    "x_BEHW = torch.rand([B, E, H, W], device='cuda')\n",
    "fmap1_BDHW = torch.rand([B, D, H, W], device=x_BEHW.device)\n",
    "fmap2_BDHW = torch.rand([B, D, H, W], device=x_BEHW.device)\n",
    "t_embd_BT = torch.rand([B, T_], device=x_BEHW.device)\n",
    "model = UNetUpsample(D, E, T_).to(x_BEHW.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dabbb796-15d9-4602-a890-0c801e83aae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BFHW = torch.cat([x_BEHW, fmap1_BDHW], dim=1)\n",
    "check_dims(x_BFHW, (B, F_, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6c918d9-f63c-4c93-9ea2-fb412ff9a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BEHW = model.block1(x_BFHW, t_embd_BT)\n",
    "check_dims(x_BEHW, (B, E, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97c49123-f8db-4ce6-8037-1ee79b6a30a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BFHW = torch.cat([x_BEHW, fmap2_BDHW], dim=1)\n",
    "check_dims(x_BFHW, (B, F_, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cee0fddf-e589-4c44-9b54-4462f7349043",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BEHW = model.block2(x_BFHW, t_embd_BT)\n",
    "check_dims(x_BEHW, (B, E, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1b19443-5029-4ae5-b637-f31f3a21deed",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BEHW = model.attn(model.norm(x_BEHW)) + x_BEHW\n",
    "check_dims(x_BEHW, (B, E, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7560cc6-81a3-4cac-a9cc-a9f1a4a30e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BDHoWo = model.usample(x_BEHW)\n",
    "check_dims(x_BDHoWo, (B, D, Ho, Wo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bca9feb2-b6ae-4371-aa71-29d5fdccaeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dims(model(x_BEHW, fmap1_BDHW, fmap2_BDHW, t_embd_BT), (B, D, Ho, Wo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e5f76-21a1-41f7-bff6-d31dcf16896d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Case 2: `is_last = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba177639-ddb7-4ff0-bf5d-258d5514fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ho, Wo = H, W\n",
    "model = UNetUpsample(D, E, T_, is_last=True).to(x_BEHW.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00d25d5a-c791-4aa9-81ee-7087b800a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dims(model(x_BEHW, fmap1_BDHW, fmap2_BDHW, t_embd_BT), (B, D, Ho, Wo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fd87e5-a27e-41ed-ba5a-5b3621001d5e",
   "metadata": {},
   "source": [
    "## UNet Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c55dd9e1-9fe5-4df2-89f5-8c160e404a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNetBlock(nn.Module):\n",
    "    '''\n",
    "    B: Batch size\n",
    "    D: dim\n",
    "    H, W: Last 2 dimensions of x\n",
    "    T: t_dim\n",
    "    '''\n",
    "    def __init__(self, dim, t_dim):\n",
    "        super().__init__()\n",
    "        self.block1 = TimeResNetBlock(dim, dim, t_dim)\n",
    "        self.block2 = TimeResNetBlock(dim, dim, t_dim)\n",
    "        self.norm = nn.GroupNorm(num_groups=1, num_channels=dim)\n",
    "        self.attn = Attention(dim)\n",
    "\n",
    "    def forward(self, x_BDHW, t_embd_BT):\n",
    "        x_BDHW = self.block1(x_BDHW, t_embd_BT)\n",
    "        x_BDHW = self.block2(x_BDHW, t_embd_BT)\n",
    "        x_BDHW = self.attn(self.norm(x_BDHW)) + x_BDHW\n",
    "        return x_BDHW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d5865-7efc-4e02-b71a-1680f086a491",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07e27e2d-035a-46cc-9d47-ac5915ad6468",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "D = 32\n",
    "H, W = 128, 128\n",
    "T_ = 128\n",
    "\n",
    "torch.manual_seed(3985)\n",
    "x_BDHW = torch.rand([B, D, H, W], device='cuda')\n",
    "t_embd_BT = torch.rand([B, T_], device=x_BDHW.device)\n",
    "model = UNetBlock(D, T_).to(x_BDHW.device)\n",
    "check_dims(model(x_BDHW, t_embd_BT), (B, D, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1295f4-c217-4a2a-b6c9-3e43ae512e4c",
   "metadata": {},
   "source": [
    "## UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3abd8635-87f6-43f6-8d2f-9ed3122dfb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    '''\n",
    "    D: dim\n",
    "    C: n_channels\n",
    "    H, W: Last 2 dimensions of x\n",
    "    T: t_dim\n",
    "    F: dim // 2\n",
    "\n",
    "    D0 = D\n",
    "    H0 = H // 2\n",
    "    W0 = W // 2\n",
    "    \n",
    "    D1 = D * 2\n",
    "    H1 = H // 4\n",
    "    W1 = W // 4\n",
    "    \n",
    "    D2 = D * 4\n",
    "    H2 = H // 8\n",
    "    W2 = W // 8\n",
    "    \n",
    "    D3 = D * 8\n",
    "    '''\n",
    "    def __init__(self, dim, n_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_conv = nn.Conv2d(n_channels, dim, kernel_size=1, padding=0)\n",
    "\n",
    "        t_dim = dim * 4\n",
    "        amp = math.log(1e4) / (dim // 2 - 1)\n",
    "        self.register_buffer(\n",
    "            'freqs_F', torch.exp(torch.arange(dim//2) * -amp)\n",
    "        )\n",
    "        self.proj_t = nn.Sequential(\n",
    "            nn.Linear(dim, t_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(t_dim, t_dim)\n",
    "        )\n",
    "\n",
    "        dim0 = dim\n",
    "        dim1 = dim * 2\n",
    "        dim2 = dim * 4\n",
    "        dim3 = dim * 8\n",
    "\n",
    "        self.dsample0 = UNetDownsample(dim0, dim0, t_dim)\n",
    "        self.dsample1 = UNetDownsample(dim0, dim1, t_dim)\n",
    "        self.dsample2 = UNetDownsample(dim1, dim2, t_dim)\n",
    "        self.dsample3 = UNetDownsample(dim2, dim3, t_dim, is_last=True)\n",
    "\n",
    "        self.mblock = UNetBlock(dim3, t_dim)\n",
    "        \n",
    "        self.usample3 = UNetUpsample(dim2, dim3, t_dim)\n",
    "        self.usample2 = UNetUpsample(dim1, dim2, t_dim)\n",
    "        self.usample1 = UNetUpsample(dim0, dim1, t_dim)\n",
    "        self.usample0 = UNetUpsample(dim0, dim0, t_dim, is_last=True)\n",
    "\n",
    "        self.out_resblk = TimeResNetBlock(2*dim, dim, t_dim)\n",
    "        self.out_conv = nn.Conv2d(dim, n_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x_BCHW, t_B):\n",
    "        pos_embd_BF = t_B.unsqueeze(1) * self.freqs_F.unsqueeze(0)\n",
    "        t_embd_BD = torch.cat([pos_embd_BF.sin(), pos_embd_BF.cos()], dim=-1)\n",
    "        t_embd_BT = self.proj_t(t_embd_BD)\n",
    "    \n",
    "        x_BDHW = self.in_conv(x_BCHW)\n",
    "        r_BDHW = x_BDHW.clone()\n",
    "\n",
    "        x_BD0H0W0, fmap2_BD0HW  , fmap1_BD0HW   = self.dsample0(x_BDHW   , t_embd_BT)\n",
    "        x_BD1H1W1, fmap2_BD0H0W0, fmap1_BD0H0W0 = self.dsample1(x_BD0H0W0, t_embd_BT)\n",
    "        x_BD2H2W2, fmap2_BD1H1W1, fmap1_BD1H1W1 = self.dsample2(x_BD1H1W1, t_embd_BT)\n",
    "        x_BD3H2W2, fmap2_BD2H2W2, fmap1_BD2H2W2 = self.dsample3(x_BD2H2W2, t_embd_BT)\n",
    "        x_BD3H2W2 = self.mblock(x_BD3H2W2, t_embd_BT)\n",
    "        x_BD2H1W1 = self.usample3(x_BD3H2W2, fmap1_BD2H2W2, fmap2_BD2H2W2, t_embd_BT)\n",
    "        x_BD1H0W0 = self.usample2(x_BD2H1W1, fmap1_BD1H1W1, fmap2_BD1H1W1, t_embd_BT)\n",
    "        x_BD0HW   = self.usample1(x_BD1H0W0, fmap1_BD0H0W0, fmap2_BD0H0W0, t_embd_BT)\n",
    "        x_BDHW    = self.usample0(x_BD0HW  , fmap1_BD0HW  , fmap2_BD0HW  , t_embd_BT)\n",
    "\n",
    "        x_BD1HW = torch.cat([x_BDHW, r_BDHW], dim=1)\n",
    "        x_BCHW = self.out_conv(self.out_resblk(x_BD1HW, t_embd_BT))\n",
    "\n",
    "        return x_BCHW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce49353f-55fb-40e0-a07e-31c2148f84ce",
   "metadata": {},
   "source": [
    "### Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65b6f9cb-7848-49e4-8df8-88e522cfa6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "C = 3\n",
    "H = 128\n",
    "W = 128\n",
    "D = 32\n",
    "T_ = 4 * D\n",
    "F_ = D / 2\n",
    "\n",
    "D0 = D\n",
    "H0 = H // 2\n",
    "W0 = W // 2\n",
    "\n",
    "D1 = D * 2\n",
    "H1 = H // 4\n",
    "W1 = W // 4\n",
    "\n",
    "D2 = D * 4\n",
    "H2 = H // 8\n",
    "W2 = W // 8\n",
    "\n",
    "D3 = D * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2088a273-7901-48e6-a292-eb44682a5c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3985)\n",
    "x_BCHW = torch.rand([2, C, H, W], device='cuda')\n",
    "t_B = torch.randint(0, 1000, [B], device=x_BCHW.device)\n",
    "model = UNet(dim=D, n_channels=C).to(x_BCHW.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1e1ab602-a3d0-4448-9960-b129094e7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_embd_BF = t_B.unsqueeze(1) * model.freqs_F.unsqueeze(0)\n",
    "check_dims(pos_embd_BF, (B, F_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea8e6d71-8bfa-403b-9e80-80da5eb2fc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_embd_BD = torch.cat([pos_embd_BF.sin(), pos_embd_BF.cos()], dim=-1)\n",
    "check_dims(t_embd_BD, (B, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9ca280ac-fc1d-4610-bfe9-293c7f54fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_embd_BT = model.proj_t(t_embd_BD)\n",
    "check_dims(t_embd_BT, (B, T_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "457fb0e8-4950-472f-9f22-8aaa427ca187",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BDHW = model.in_conv(x_BCHW)\n",
    "check_dims(x_BDHW, (B, D, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f1e6e08-7877-46ae-ad99-f283986937c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_BDHW = x_BDHW.clone()\n",
    "check_dims(r_BDHW, (B, D, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cbd1108f-4c3b-4e00-afa3-52f0030d4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BD0H0W0, fmap1_BD0HW, fmap2_BD0HW = model.dsample0(x_BDHW, t_embd_BT)\n",
    "check_dims(x_BD0H0W0, (B, D0, H0, W0))\n",
    "check_dims(fmap1_BD0HW, (B, D0, H, W))\n",
    "check_dims(fmap2_BD0HW, (B, D0, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55021b85-01d5-4c03-92d4-1fa3f5fb1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BD1H1W1, fmap1_BD0H0W0, fmap2_BD0H0W0 = model.dsample1(x_BD0H0W0, t_embd_BT)\n",
    "check_dims(x_BD1H1W1, (B, D1, H1, W1))\n",
    "check_dims(fmap1_BD0H0W0, (B, D0, H0, W0))\n",
    "check_dims(fmap2_BD0H0W0, (B, D0, H0, W0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4409d12a-a893-4fd5-92cd-18ab6a77e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BD2H2W2, fmap1_BD1H1W1, fmap2_BD1H1W1 = model.dsample2(x_BD1H1W1, t_embd_BT)\n",
    "check_dims(x_BD2H2W2, (B, D2, H2, W2))\n",
    "check_dims(fmap1_BD1H1W1, (B, D1, H1, W1))\n",
    "check_dims(fmap2_BD1H1W1, (B, D1, H1, W1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5740d2e-4930-45d0-82dd-56ab4959fbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BD3H2W2, fmap1_BD2H2W2, fmap2_BD2H2W2 = model.dsample3(x_BD2H2W2, t_embd_BT)\n",
    "check_dims(x_BD3H2W2, (B, D3, H2, W2))\n",
    "check_dims(fmap1_BD2H2W2, (B, D2, H2, W2))\n",
    "check_dims(fmap2_BD2H2W2, (B, D2, H2, W2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "662a2f89-c687-4e8e-b8ea-e171289f78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BD3H2W2 = model.mblock(x_BD3H2W2, t_embd_BT)\n",
    "check_dims(x_BD3H2W2, (B, D3, H2, W2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1731eb18-0f72-47dc-af32-f5b87a58b7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BD2H1W1 = model.usample3(x_BD3H2W2, fmap1_BD2H2W2, fmap2_BD2H2W2, t_embd_BT)\n",
    "check_dims(x_BD2H1W1, (B, D2, H1, W1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2b2112e6-fd57-48eb-a42f-cf17159208e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BD1H0W0 = model.usample2(x_BD2H1W1, fmap1_BD1H1W1, fmap2_BD1H1W1, t_embd_BT)\n",
    "check_dims(x_BD1H0W0, (B, D1, H0, W0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b113d22d-0af0-44b2-b436-b0457c9a1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BD0HW = model.usample1(x_BD1H0W0, fmap1_BD0H0W0, fmap2_BD0H0W0, t_embd_BT)\n",
    "check_dims(x_BD0HW, (B, D0, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5fc7f1f-50a4-42b1-9d5e-e2c3daf05cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BDHW = model.usample0(x_BD0HW, fmap1_BD0HW, fmap2_BD0HW, t_embd_BT)\n",
    "check_dims(x_BDHW, (B, D, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "101c9589-88ba-416b-8fb9-953458af291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BD1HW = torch.cat([x_BDHW, r_BDHW], dim=1)\n",
    "check_dims(x_BD1HW, (B, D1, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f35df836-9686-4864-b2b3-f26bdd9d55f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_BCHW = model.out_conv(model.out_resblk(x_BD1HW, t_embd_BT))\n",
    "check_dims(x_BCHW, (B, C, H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26795d76-17d0-4460-9d4e-917ea8608658",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dims(model(x_BCHW, t_B), (B, C, H, W))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
